---
title: 一个数据分析实例
date: 2018-04-12 13:00:00
---

 学以致用，才是正理。最近用了解的数据处理和机器学习知识做了两个小案例。这里就一个为例记下我的心得。

 ### 数据背景
 1. 输入有4个参数，输出1个。 
 2. 数据记录共有60多条。

 ## *心得*
 1. 数据预处理是个不可忽略的活。
    1. 有的记录参数不完整，要么剔除，要么补全。
    2. 有的记录完整，但由于某种原因不可用，得去掉。最后剩下可用的就50条记录。
    3. 有的记录里的数据还得做预-预处理。

2. 输出一个参数，但是粗可分为10类，也就是说可以当作分类问题，比如输出1，2，到10；但是如果当作回归问题，可以得到更精细的结果，比如可以得到1.6， 4.2这样的结果，对问题解决更好。

3. 如果当作回归问题，貌似Keras不是最擅长。（原来没注意到这个问题，做起来后才了解到Keras用来处理分类最好)。至于Keras+Tensorflow到底处理回归问题怎么样还得了解下。

4. 那么就决定用sci-learn 里面的模型来分析下了。主要试验了这几个模型，单纯线性模型，线性-ridge模型，线性-lasso模型，线性-贝因斯模型，加Polynomial-线性模型。
    1. 结果相差不大，score.accuracy都在0.7-0.8左右，最高没过0.83的。
    2. 加regulation (如ridge, lasso), 或加多次项（polynomial),效果会好些，几个0.8以上的分数都是它们出来的。（通过观察可视化数据，感觉基本上还是接近一次/二次的分布。测试中让Polynomial上了3，果然就脱轨了:)）
    3. 对数据进行normalize/scale的预处理帮助也不明显。

5. 由于期望模型能对以后来的新数据做预测，所以如果在训练的时候对训练数据做预处理，好像对以后的预测带来“输入上”的不方便，因为不是每种预处理都能容易的用到到新（单个）数据上。

6. 使用K-fold的效果没用，观察了下，基本确定是由于数据量太小的原因。CV一过2就会产生很大误差而不可用。

7. 做到后来发现一个没想到的问题：就是用不同的模型/方法去训练，出来的结果依据什么标准比较（哪个模型/方法适用些，哪个不适用）。这个还有待进一步了解。

8. 本来是想用Keras(后段用Tensorflow)来高射炮打蚊子的，没想到没用橙成。而且后来想想，数据量太小，可能就是高射炮用上也没用，不到一定的数据量，可能深度学习就拿不到有价值的特征出来。这个判断不知对否？
